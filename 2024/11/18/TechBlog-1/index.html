<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Basic intro and experiment of CVIn this blog, a simple CV process will be applied for object detection. From a basic image gradient vector, followed by image segmentation, and finally a example of obj">
<meta property="og:type" content="article">
<meta property="og:title" content="TechBlog 1">
<meta property="og:url" content="http://example.com/2024/11/18/TechBlog-1/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="Basic intro and experiment of CVIn this blog, a simple CV process will be applied for object detection. From a basic image gradient vector, followed by image segmentation, and finally a example of obj">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/mygo1.jpg">
<meta property="og:image" content="http://example.com/gradient_res.png">
<meta property="og:image" content="http://example.com/iceland.jpg">
<meta property="og:image" content="http://example.com/seg.png">
<meta property="og:image" content="http://example.com/puppy.jpg">
<meta property="og:image" content="http://example.com/vgg_res_1.png">
<meta property="og:image" content="http://example.com/cat.jpg">
<meta property="og:image" content="http://example.com/vgg_res_2.png">
<meta property="og:image" content="http://example.com/saber.jpg">
<meta property="og:image" content="http://example.com/vgg_res_3.png">
<meta property="article:published_time" content="2024-11-18T08:42:49.000Z">
<meta property="article:modified_time" content="2024-11-18T08:54:20.541Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/mygo1.jpg">


<link rel="canonical" href="http://example.com/2024/11/18/TechBlog-1/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2024/11/18/TechBlog-1/","path":"2024/11/18/TechBlog-1/","title":"TechBlog 1"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>TechBlog 1 | Hexo</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Hexo</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Basic-intro-and-experiment-of-CV"><span class="nav-number">1.</span> <span class="nav-text">Basic intro and experiment of CV</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Image-Gradient-Vector"><span class="nav-number">1.1.</span> <span class="nav-text">Image Gradient Vector</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Image-Segmentation"><span class="nav-number">1.2.</span> <span class="nav-text">Image Segmentation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Image-Classification"><span class="nav-number">1.3.</span> <span class="nav-text">Image Classification</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">1.4.</span> <span class="nav-text">Reference</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">John Doe</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/11/18/TechBlog-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="John Doe">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="TechBlog 1 | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          TechBlog 1
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-11-18 16:42:49 / Modified: 16:54:20" itemprop="dateCreated datePublished" datetime="2024-11-18T16:42:49+08:00">2024-11-18</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h1 id="Basic-intro-and-experiment-of-CV"><a href="#Basic-intro-and-experiment-of-CV" class="headerlink" title="Basic intro and experiment of CV"></a>Basic intro and experiment of CV</h1><p>In this blog, a simple CV process will be applied for object detection. From a basic image gradient vector, followed by image segmentation, and finally a example of object detection using VGG. <br></p>
<h2 id="Image-Gradient-Vector"><a href="#Image-Gradient-Vector" class="headerlink" title="Image Gradient Vector"></a>Image Gradient Vector</h2><ul>
<li><p><strong>Gradient</strong>: The direction of gradient is the greatest change rate of the function, which is used to find the extremum. <herf></p>
</li>
<li><p><strong>Image Gradient Vector</strong>: Take the image as a function, <strong>gradient</strong> can be used to measure the <strong>pixel</strong>‘s change rate. Image gradient can be regarded as a two-dimensional discrete function, and image gradient is actually the derivative of this two-dimensional discrete function $f(x, y)$.  <herf><br>$$<br>\nabla f(x,y) &#x3D; [G_x, G_y]^T &#x3D; [{\partial f\over \partial x}, {\partial f\over \partial y}]^T<br>$$</p>
<p>Take the <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Sobel_operator"><strong>Sobel operator</strong></a> for an example, which mainly used for <em>edge detection</em>, is a discrete difference operator used to calculate the grayscale approximation of the image gradient function. <herf></p>
</li>
</ul>
<p>$$<br>G_x &#x3D;<br>\left[<br>    \begin{array} {ccc}<br>    -1 &amp; 0 &amp; 1 \<br>    -2 &amp; 0 &amp; 2 \<br>    -1 &amp; 0 &amp; 1<br>    \end{array}<br>\right] * A<br>$$<br>$$<br>G_x &#x3D;<br>\left[<br>    \begin{array} {ccc}<br>    -1 &amp; -2 &amp; -1 \<br>     0 &amp;  0 &amp;  0 \<br>     1 &amp;  2 &amp;  1<br>    \end{array}<br>\right] * A<br>$$<br>Calculation for an image $G &#x3D; \sqrt{ {G_x}^2 + {G_y}^2}$.</p>
<ul>
<li><strong>Image Process Example</strong>: here using an example to see the different between applying $G_x$ and $G_y$ to process image pixel.<br>The example image is: <img src="/./mygo1.jpg" alt="mygo" title="mygo1"><br>Code for this:  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> scipy.signal <span class="keyword">as</span> sig</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img = scipy.misc.imread(<span class="string">&quot;mygo1.jpg&quot;</span>, mode=<span class="string">&quot;L&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the Sobel operator kernels.</span></span><br><span class="line">kernel_x = np.array([ [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],[-<span class="number">2</span>, <span class="number">0</span>, <span class="number">2</span>],[-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>] ])</span><br><span class="line">kernel_y = np.array([ [<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>], [-<span class="number">1</span>, -<span class="number">2</span>, -<span class="number">1</span>] ])</span><br><span class="line"></span><br><span class="line">G_x = sig.convolve2d(img, kernel_x, mode=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line">G_y = sig.convolve2d(img, kernel_y, mode=<span class="string">&#x27;same&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Plot </span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax1 = fig.add_subplot(<span class="number">121</span>)</span><br><span class="line">ax2 = fig.add_subplot(<span class="number">122</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># the transformation (G_x + 255) / 2.</span></span><br><span class="line">ax1.imshow((G_x + <span class="number">255</span>) / <span class="number">2</span>, cmap=<span class="string">&#x27;gray&#x27;</span>); ax1.set_xlabel(<span class="string">&quot;Gx&quot;</span>)</span><br><span class="line">ax2.imshow((G_y + <span class="number">255</span>) / <span class="number">2</span>, cmap=<span class="string">&#x27;gray&#x27;</span>); ax2.set_xlabel(<span class="string">&quot;Gy&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
  The result shows the comparation of using $G_x$ and $G_y$. <br><br>  <img src="/./gradient_res.png" alt="gradient" title="mygo_res"></li>
</ul>
<h2 id="Image-Segmentation"><a href="#Image-Segmentation" class="headerlink" title="Image Segmentation"></a>Image Segmentation</h2><p><a target="_blank" rel="noopener" href="https://cs.brown.edu/people/pfelzens/segment/">Felzenszwalb’s Algorithm</a> was proposed for segmenting an image into similar regions. Each pixel is a vertex and then gradually merged to create a region, and the connection between each pixel is a <a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Minimum_spanning_tree">minimum spanning trss (MST)</a>. </p>
<ul>
<li><strong>How to Balance Difference bwtween two Pixels</strong> <br><br><strong>Difinations</strong>: <ul>
<li><strong>Internal Difference</strong>: $Int(C) &#x3D; max_{e\in (MST, E)} e$, which represents the edge with the greatest dissimilarity in MST.</li>
<li><strong>Difference between two components</strong>: $Diff(C1, C2) &#x3D; min_{(v_i\in C1) (v_j\in C2) ((v_i, v_j)\in E)} \omega (v_i, v_j)$, which represents the dissimilarity of the edge that connects all the edges of the two regions, the dissimilarity of the edge with the least dissimilarity. The dissimilarity of the two regions where they are most similar.</li>
</ul>
</li>
</ul>
<p> The standard for merging two regions $(C_i, C_j)$ is:<br> $$ Diff(C_i, C_j) \lt Min(Int(C_i), Int(C_j)) $$<br> Only when $Int(C_i)$ and $Int(C_j)$ are able to stand the $Diff(C_i, C_j)$, they will be segmented into different regions. Otherwise, they are regarded as in the same region. <br></p>
<ul>
<li><p><strong>Procedures of Algorithm</strong><br>  Given $G &#x3D; (V, E)$, $|V| &#x3D; n$ and $|E| &#x3D; m$.</p>
<ol>
<li>edges are sorted by dissimilarity (non-desconding), labeled as $e_1, e_2, \cdots ,e_m$,</li>
<li>choose $e_i$,</li>
<li>determines the currently selected edges $e_i &#x3D; (v_i, v_j)$ for merging if meets:<ol>
<li>$Id(v_i) \neq Id(v_j)$</li>
<li>the degree of dissimilarity is not greater than the degree of dissimilarity within the two $\omega_(i, j) \leq Mint(C_i, C_j)$, then step <strong>4</strong>. Otherwise, straight to step <strong>5</strong>.</li>
</ol>
</li>
<li>update <em>thresholds</em> and class <em>designators</em>:<br> class designators: $Id(v_i) Id(v_j)$ -&gt; $Id(v_i)$,</li>
<li>if $n \leq N$, select the next edge to go to step <strong>3</strong>.</li>
</ol>
</li>
<li><p><strong>Example Code</strong> <br><br>Applying <a target="_blank" rel="noopener" href="https://scikit-image.org/docs/dev/api/skimage.segmentation.html#skimage.segmentation.felzenszwalb">skimage segmentation</a> to segment the example image. Set k &#x3D; 100 and 500 to see how controlled merge-region size represents.  <br><br>The example image used for segmentation is:<br><img src="/./iceland.jpg" alt="iceland" title="iceland">    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> scipy</span><br><span class="line"><span class="keyword">import</span> scipy.signal <span class="keyword">as</span> sig</span><br><span class="line"><span class="keyword">import</span> skimage.segmentation</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">img2 = scipy.misc.imread(<span class="string">&quot;mygo1.jpg&quot;</span>, mode=<span class="string">&quot;L&quot;</span>)</span><br><span class="line">segment_mask1 = skimage.segmentation.felzenszwalb(img2, scale=<span class="number">100</span>)</span><br><span class="line">segment_mask2 = skimage.segmentation.felzenszwalb(img2, scale=<span class="number">1000</span>)</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</span><br><span class="line">ax1 = fig.add_subplot(<span class="number">121</span>)</span><br><span class="line">ax2 = fig.add_subplot(<span class="number">122</span>)</span><br><span class="line">ax1.imshow(segment_mask1); ax1.set_xlabel(<span class="string">&quot;k=100&quot;</span>)</span><br><span class="line">ax2.imshow(segment_mask2); ax2.set_xlabel(<span class="string">&quot;k=500&quot;</span>)</span><br><span class="line">fig.suptitle(<span class="string">&quot;Felsenszwalb&#x27;s efficient graph based image segmentation&quot;</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Segment result (k &#x3D; 100 &amp; k &#x3D; 500):<br><img src="/./seg.png" alt="seg" title="seg_res"></p>
</li>
</ul>
<h2 id="Image-Classification"><a href="#Image-Classification" class="headerlink" title="Image Classification"></a>Image Classification</h2><ul>
<li><p><strong>CNN for Image Classification</strong> <br><br><strong>Convolution operation</strong>: As we learned from the course, in short, convolution applies element-wise multiplication for the vector&#x2F; matrix and then<br>summation.</p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1409.1556"><strong>VGG</strong></a> (Visual Geometry Group) <br><br>Using 3*3 convoluton layer and 2*2 pooling layer. VGG has two structures, namely VGG16 and VGG19, and there is no essential difference between the two, but the network depth is different. <br><br>Why small size works better: each convolutional layer passes through an <em>activation function</em>. The activation function is a <em>nonlinear transformation</em>. The ability to be non-linear is stronger. <br></p>
</li>
<li><p><strong>Example Code</strong> <br><br>Here I use VGG16 to implement a simple classficatoin for animals. The <em>npy file</em> and a <em>class file</em> for choosing results were downloaded from <a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~frossard/post/vgg16/">here</a>. <br><br>VGG16 contains 16 hidden layers (13 convolutional layers and 3 fully connected layers). <br><br>The code for test is from <a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~frossard/vgg16/vgg16.py">here</a>. I downloaded 3 images from google for test. Minor changed code for classifiication:</p>
</li>
</ul>
<details> 
<summary><font size="4" color="orange">Show Code</font></summary> 
<pre><code class="language-cpp">

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow.compat.v1 <span class="keyword">as</span> tf</span><br><span class="line">tf.disable_v2_behavior()</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> imread, imresize, toimage</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> skimage</span><br><span class="line"><span class="keyword">import</span> skimage.io</span><br><span class="line"><span class="keyword">import</span> skimage.transform</span><br><span class="line"><span class="keyword">from</span> imageClass <span class="keyword">import</span> class_names</span><br><span class="line"></span><br><span class="line">VGG_MEAN = [<span class="number">103.939</span>, <span class="number">116.779</span>, <span class="number">123.68</span>]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGG16</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    The VGG16 model for image classification</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, vgg16_npy_path=<span class="literal">None</span>, trainable=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        :param vgg16_npy_path: string, vgg16_npz path</span></span><br><span class="line"><span class="string">        :param trainable: bool, construct a trainable model if True</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># The pretained data</span></span><br><span class="line">        <span class="keyword">if</span> vgg16_npy_path <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="variable language_">self</span>._data_dict = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>._data_dict = np.load(vgg16_npy_path, encoding=<span class="string">&quot;latin1&quot;</span>, allow_pickle= <span class="literal">True</span>).item()</span><br><span class="line">        <span class="variable language_">self</span>.trainable = trainable</span><br><span class="line">        <span class="comment"># Keep all trainable parameters</span></span><br><span class="line">        <span class="variable language_">self</span>._var_dict = &#123;&#125;</span><br><span class="line">        <span class="variable language_">self</span>.__bulid__()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__bulid__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        The inner method to build VGG16 model</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># input and output</span></span><br><span class="line">        <span class="variable language_">self</span>._x = tf.placeholder(tf.float32, shape=[<span class="literal">None</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>])</span><br><span class="line">        <span class="variable language_">self</span>._y = tf.placeholder(tf.int64, shape=[<span class="literal">None</span>, ])</span><br><span class="line">        <span class="comment"># Data preprocessiing</span></span><br><span class="line">        mean = tf.constant([<span class="number">103.939</span>, <span class="number">116.779</span>, <span class="number">123.68</span>], dtype=tf.float32, shape=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line">        x = <span class="variable language_">self</span>._x - mean</span><br><span class="line">        <span class="variable language_">self</span>._train_mode = tf.placeholder(tf.<span class="built_in">bool</span>)  <span class="comment"># use training model is True, otherwise test model</span></span><br><span class="line">        <span class="comment"># construct model</span></span><br><span class="line">        conv1_1 = <span class="variable language_">self</span>._conv_layer(x, <span class="number">3</span>, <span class="number">64</span>, <span class="string">&quot;conv1_1&quot;</span>)</span><br><span class="line">        conv1_2 = <span class="variable language_">self</span>._conv_layer(conv1_1, <span class="number">64</span>, <span class="number">64</span>, <span class="string">&quot;conv1_2&quot;</span>)</span><br><span class="line">        pool1 = <span class="variable language_">self</span>._max_pool(conv1_2, <span class="string">&quot;pool1&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv2_1 = <span class="variable language_">self</span>._conv_layer(pool1, <span class="number">64</span>, <span class="number">128</span>, <span class="string">&quot;conv2_1&quot;</span>)</span><br><span class="line">        conv2_2 = <span class="variable language_">self</span>._conv_layer(conv2_1, <span class="number">128</span>, <span class="number">128</span>, <span class="string">&quot;conv2_2&quot;</span>)</span><br><span class="line">        pool2 = <span class="variable language_">self</span>._max_pool(conv2_2, <span class="string">&quot;pool2&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv3_1 = <span class="variable language_">self</span>._conv_layer(pool2, <span class="number">128</span>, <span class="number">256</span>, <span class="string">&quot;conv3_1&quot;</span>)</span><br><span class="line">        conv3_2 = <span class="variable language_">self</span>._conv_layer(conv3_1, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&quot;conv3_2&quot;</span>)</span><br><span class="line">        conv3_3 = <span class="variable language_">self</span>._conv_layer(conv3_2, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&quot;conv3_3&quot;</span>)</span><br><span class="line">        pool3 = <span class="variable language_">self</span>._max_pool(conv3_3, <span class="string">&quot;pool3&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv4_1 = <span class="variable language_">self</span>._conv_layer(pool3, <span class="number">256</span>, <span class="number">512</span>, <span class="string">&quot;conv4_1&quot;</span>)</span><br><span class="line">        conv4_2 = <span class="variable language_">self</span>._conv_layer(conv4_1, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&quot;conv4_2&quot;</span>)</span><br><span class="line">        conv4_3 = <span class="variable language_">self</span>._conv_layer(conv4_2, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&quot;conv4_3&quot;</span>)</span><br><span class="line">        pool4 = <span class="variable language_">self</span>._max_pool(conv4_3, <span class="string">&quot;pool4&quot;</span>)</span><br><span class="line"></span><br><span class="line">        conv5_1 = <span class="variable language_">self</span>._conv_layer(pool4, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&quot;conv5_1&quot;</span>)</span><br><span class="line">        conv5_2 = <span class="variable language_">self</span>._conv_layer(conv5_1, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&quot;conv5_2&quot;</span>)</span><br><span class="line">        conv5_3 = <span class="variable language_">self</span>._conv_layer(conv5_2, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&quot;conv5_3&quot;</span>)</span><br><span class="line">        pool5 = <span class="variable language_">self</span>._max_pool(conv5_3, <span class="string">&quot;pool5&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># n_in = ((224 / (2**5)) ** 2) * 512</span></span><br><span class="line">        fc6 = <span class="variable language_">self</span>._fc_layer(pool5, <span class="number">25088</span>, <span class="number">4096</span>, <span class="string">&quot;fc6&quot;</span>, act=tf.nn.relu, reshaped=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># Use train_mode to control</span></span><br><span class="line">        fc6 = tf.cond(<span class="variable language_">self</span>._train_mode, <span class="keyword">lambda</span>: tf.nn.dropout(fc6, <span class="number">0.5</span>), <span class="keyword">lambda</span>: fc6)</span><br><span class="line">        fc7 = <span class="variable language_">self</span>._fc_layer(fc6, <span class="number">4096</span>, <span class="number">4096</span>, <span class="string">&quot;fc7&quot;</span>, act=tf.nn.relu)</span><br><span class="line">        fc7 = tf.cond(<span class="variable language_">self</span>._train_mode, <span class="keyword">lambda</span>: tf.nn.dropout(fc7, <span class="number">0.5</span>), <span class="keyword">lambda</span>: fc7)</span><br><span class="line">        fc8 = <span class="variable language_">self</span>._fc_layer(fc7, <span class="number">4096</span>, <span class="number">1000</span>, <span class="string">&quot;fc8&quot;</span>, act=tf.identity)</span><br><span class="line"></span><br><span class="line">        <span class="variable language_">self</span>._prob = tf.nn.softmax(fc8, name=<span class="string">&quot;prob&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.trainable:</span><br><span class="line">            <span class="variable language_">self</span>._cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(fc8, <span class="variable language_">self</span>._y))</span><br><span class="line">            correct_pred = tf.equal(<span class="variable language_">self</span>._y, tf.argmax(<span class="variable language_">self</span>._prob, <span class="number">1</span>))</span><br><span class="line">            <span class="variable language_">self</span>._accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="variable language_">self</span>._cost = <span class="literal">None</span></span><br><span class="line">            <span class="variable language_">self</span>._accuracy = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_conv_layer</span>(<span class="params">self, inpt, in_channels, out_channels, name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Create conv layer</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name):</span><br><span class="line">            filters, biases = <span class="variable language_">self</span>._get_conv_var(<span class="number">3</span>, in_channels, out_channels, name)</span><br><span class="line">            conv_output = tf.nn.conv2d(inpt, filters, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">&quot;SAME&quot;</span>)</span><br><span class="line">            conv_output = tf.nn.bias_add(conv_output, biases)</span><br><span class="line">            conv_output = tf.nn.relu(conv_output)</span><br><span class="line">        <span class="keyword">return</span> conv_output</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_fc_layer</span>(<span class="params">self, inpt, n_in, n_out, name, act=tf.nn.relu, reshaped=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Create fully connected layer&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> reshaped:</span><br><span class="line">            inpt = tf.reshape(inpt, shape=[-<span class="number">1</span>, n_in])</span><br><span class="line">        <span class="keyword">with</span> tf.variable_scope(name):</span><br><span class="line">            weights, biases = <span class="variable language_">self</span>._get_fc_var(n_in, n_out, name)</span><br><span class="line">            output = tf.matmul(inpt, weights) + biases</span><br><span class="line">        <span class="keyword">return</span> act(output)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_avg_pool</span>(<span class="params">self, inpt, name</span>):</span><br><span class="line">        <span class="keyword">return</span> tf.nn.avg_pool(inpt, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">&quot;SAME&quot;</span>,</span><br><span class="line">                              name=name)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_max_pool</span>(<span class="params">self, inpt, name</span>):</span><br><span class="line">        <span class="keyword">return</span> tf.nn.max_pool(inpt, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">&quot;SAME&quot;</span>,</span><br><span class="line">                              name=name)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_fc_var</span>(<span class="params">self, n_in, n_out, name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;Get the weights and biases of fully connected layer&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.trainable:</span><br><span class="line">            init_weights = tf.truncated_normal([n_in, n_out], <span class="number">0.0</span>, <span class="number">0.001</span>)</span><br><span class="line">            init_biases = tf.truncated_normal([n_out, ], <span class="number">0.0</span>, <span class="number">0.001</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            init_weights = <span class="literal">None</span></span><br><span class="line">            init_biases = <span class="literal">None</span></span><br><span class="line">        weights = <span class="variable language_">self</span>._get_var(init_weights, name, <span class="number">0</span>, name + <span class="string">&quot;_weights&quot;</span>)</span><br><span class="line">        biases = <span class="variable language_">self</span>._get_var(init_biases, name, <span class="number">1</span>, name + <span class="string">&quot;_biases&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> weights, biases</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_conv_var</span>(<span class="params">self, filter_size, in_channels, out_channels, name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Get the filter and bias of conv layer</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.trainable:</span><br><span class="line">            initial_value_filter = tf.truncated_normal([filter_size, filter_size, in_channels, out_channels], <span class="number">0.0</span>,</span><br><span class="line">                                                       <span class="number">0.001</span>)</span><br><span class="line">            initial_value_bias = tf.truncated_normal([out_channels, ], <span class="number">0.0</span>, <span class="number">0.001</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            initial_value_filter = <span class="literal">None</span></span><br><span class="line">            initial_value_bias = <span class="literal">None</span></span><br><span class="line">        filters = <span class="variable language_">self</span>._get_var(initial_value_filter, name, <span class="number">0</span>, name + <span class="string">&quot;_filters&quot;</span>)</span><br><span class="line">        biases = <span class="variable language_">self</span>._get_var(initial_value_bias, name, <span class="number">1</span>, name + <span class="string">&quot;_biases&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> filters, biases</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_var</span>(<span class="params">self, initial_value, name, idx, var_name</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Use this method to construct variable parameters</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>._data_dict <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            value = <span class="variable language_">self</span>._data_dict[name][idx]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            value = initial_value</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="variable language_">self</span>.trainable:</span><br><span class="line">            var = tf.Variable(value, dtype=tf.float32, name=var_name)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            var = tf.constant(value, dtype=tf.float32, name=<span class="string">&quot;var_name&quot;</span>)</span><br><span class="line">        <span class="comment"># Save</span></span><br><span class="line">        <span class="variable language_">self</span>._var_dict[(name, idx)] = var</span><br><span class="line">        <span class="keyword">return</span> var</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_train_op</span>(<span class="params">self, lr=<span class="number">0.01</span></span>):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.trainable:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">return</span> tf.train.GradientDescentOptimizer(lr).minimize(<span class="variable language_">self</span>.cost,</span><br><span class="line">                                                              var_list=<span class="built_in">list</span>(<span class="variable language_">self</span>._var_dict.values()))</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">input</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._x</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">target</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._y</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">train_mode</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._train_mode</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._accuracy</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">cost</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._cost</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">prob</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>._prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># returns image of shape [224, 224, 3]</span></span><br><span class="line"><span class="comment"># [height, width, depth]</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_image</span>(<span class="params">path</span>):</span><br><span class="line">    <span class="comment"># load image</span></span><br><span class="line">    img = skimage.io.imread(path)</span><br><span class="line">    img = img / <span class="number">255.0</span></span><br><span class="line">    <span class="comment"># assert (0 &lt;= img).all() and (img &lt;= 1.0).all()</span></span><br><span class="line">    <span class="comment"># print &quot;Original Image Shape: &quot;, img.shape</span></span><br><span class="line">    <span class="comment"># we crop image from center</span></span><br><span class="line">    short_edge = <span class="built_in">min</span>(img.shape[:<span class="number">2</span>])</span><br><span class="line">    yy = <span class="built_in">int</span>((img.shape[<span class="number">0</span>] - short_edge) / <span class="number">2</span>)</span><br><span class="line">    xx = <span class="built_in">int</span>((img.shape[<span class="number">1</span>] - short_edge) / <span class="number">2</span>)</span><br><span class="line">    crop_img = img[yy: yy + short_edge, xx: xx + short_edge]</span><br><span class="line">    <span class="comment"># resize to 224, 224</span></span><br><span class="line">    resized_img = skimage.transform.resize(crop_img, (<span class="number">224</span>, <span class="number">224</span>))</span><br><span class="line">    <span class="keyword">return</span> resized_img</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_not_trainable_vgg16</span>():</span><br><span class="line">    path = <span class="string">&quot;D:/PyCharm Community Edition 2024.1.3/TechBlog&quot;</span></span><br><span class="line">    img1 = load_image(path + <span class="string">&quot;/puppy.jpg&quot;</span>) * <span class="number">255.0</span></span><br><span class="line">    batch1 = img1.reshape((<span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    tf.compat.v1.disable_eager_execution()</span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default(), tf.compat.v1.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        vgg = VGG16(path + <span class="string">&quot;/vgg16.npy&quot;</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">        probs = sess.run(vgg.prob, feed_dict=&#123;vgg.<span class="built_in">input</span>: batch1, vgg.train_mode: <span class="literal">False</span>&#125;)</span><br><span class="line">        <span class="keyword">for</span> i, prob <span class="keyword">in</span> <span class="built_in">enumerate</span>([probs[<span class="number">0</span>]]):</span><br><span class="line">            preds = (np.argsort(prob)[::-<span class="number">1</span>])[<span class="number">0</span>:<span class="number">5</span>]</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;The&quot;</span> + <span class="built_in">str</span>(i + <span class="number">1</span>) + <span class="string">&quot; image:&quot;</span>)</span><br><span class="line">            <span class="keyword">for</span> p <span class="keyword">in</span> preds:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;\t&quot;</span>, p, class_names[p], prob[p])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    path = <span class="string">&quot;D:/PyCharm Community Edition 2024.1.3/TechBlog&quot;</span></span><br><span class="line">    img1 = load_image(path + <span class="string">&quot;/puppy.jpg&quot;</span>) * <span class="number">255.0</span></span><br><span class="line">    batch1 = img1.reshape((<span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>))</span><br><span class="line">    x = np.concatenate((batch1), <span class="number">0</span>)</span><br><span class="line">    y = np.array([<span class="number">292</span>, <span class="number">611</span>], dtype=np.int64)</span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            vgg = VGG16(path + <span class="string">&quot;/vgg16.npy&quot;</span>, trainable=<span class="literal">True</span>)</span><br><span class="line">            sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">            train_op = vgg.get_train_op(lr=<span class="number">0.0001</span>)</span><br><span class="line">            _, cost = sess.run([train_op, vgg.cost], feed_dict=&#123;vgg.<span class="built_in">input</span>: x,</span><br><span class="line">                                                                vgg.target: y, vgg.train_mode: <span class="literal">True</span>&#125;)</span><br><span class="line">            accuracy = sess.run(vgg.accuracy, feed_dict=&#123;vgg.<span class="built_in">input</span>: x,</span><br><span class="line">                                                         vgg.target: y, vgg.train_mode: <span class="literal">False</span>&#125;)</span><br><span class="line">            <span class="built_in">print</span>(cost, accuracy)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
 </code>
</pre> </details>

<p>Example images for VGG16: <br></p>
<ol>
<li><p>Puppy <br><br><img src="/./puppy.jpg" alt="puppy" title="puppy"><br><img src="/./vgg_res_1.png" alt="vgg1" title="res1"><br>The results generated by VGG16 was a “<strong>Japanese spaniel</strong>“.</p>
</li>
<li><p>Cat <br><br><img src="/./cat.jpg" alt="cat" title="cat"><br><img src="/./vgg_res_2.png" alt="res2" title="res2"><br>The results generated by VGG16 was a “<strong>Egyptian cat</strong>“.</p>
</li>
<li><p>Saber <br><br><img src="/./saber.jpg" alt="saber" title="saber"><br><img src="/./vgg_res_3.png" alt="res3" title="res3"><br>Sadly, it only implement object detection known in the <em>class file</em> to the image instead of recognition of Saber. To make it successful, dataset for her need to be collected for training. <br></p>
</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a target="_blank" rel="noopener" href="https://mccormickml.com/2013/05/07/gradient-vectors/">Gradient Vector</a></p>
<p>[2] Pedro F. Felzenszwalb, and Daniel P. Huttenlocher. “Efficient graph-based image segmentation.” Intl. journal of computer vision 59.2 (2004): 167-181.<a target="_blank" rel="noopener" href="http://cvcl.mit.edu/SUNSeminar/Felzenszwalb_IJCV04.pdf">article</a></p>
<p>[3] 图像分割—基于图的图像分割 <a target="_blank" rel="noopener" href="https://blog.csdn.net/ttransposition/article/details/38024557">blog address</a></p>
<p>[4] Simonyan, K. (2014). Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556.</p>
<p>[5] <a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~frossard/post/vgg16/">VGG in TensorFlow</a></p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/11/18/hello-world/" rel="prev" title="Hello World">
                  <i class="fa fa-angle-left"></i> Hello World
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">John Doe</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
